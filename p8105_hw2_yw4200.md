P8105_hw2_yw4200
================
yh
2023-09-27

## Problem 1

This problem uses the FiveThirtyEight data; these data were gathered to
create the interactive graphic on this page. In particular, we’ll use
the data in pols-month.csv, unemployment.csv, and snp.csv. Our goal is
to merge these into a single data frame using year and month as keys
across datasets.

First, clean the data in pols-month.csv. Use separate() to break up the
variable mon into integer variables year, month, and day; replace month
number with month name; create a president variable taking values gop
and dem, and remove prez_dem and prez_gop; and remove the day variable.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
# clean the data in pols-month.csv
pols_data = read_csv(file = "./local_data/fivethirtyeight_datasets/pols-month.csv")
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(pols_data)
```

    ## # A tibble: 6 × 9
    ##   mon        prez_gop gov_gop sen_gop rep_gop prez_dem gov_dem sen_dem rep_dem
    ##   <date>        <dbl>   <dbl>   <dbl>   <dbl>    <dbl>   <dbl>   <dbl>   <dbl>
    ## 1 1947-01-15        0      23      51     253        1      23      45     198
    ## 2 1947-02-15        0      23      51     253        1      23      45     198
    ## 3 1947-03-15        0      23      51     253        1      23      45     198
    ## 4 1947-04-15        0      23      51     253        1      23      45     198
    ## 5 1947-05-15        0      23      51     253        1      23      45     198
    ## 6 1947-06-15        0      23      51     253        1      23      45     198

``` r
# break up the variable mon
pols_data <- separate(pols_data,mon,into = c("year","month","day"),sep = '-')
pols_data$year <- as.integer(pols_data$year)
pols_data$month <- as.integer(pols_data$month)
pols_data$day <- as.integer(pols_data$day)

# replace month number with month name
pols_data$month <- month.name[pols_data$month]

#create a president variable, remove prez_dem and prez_gop and the day variable
library(dplyr)
pols_data <- pols_data |> 
  mutate(president = ifelse(prez_gop > prez_dem,"gop","dem")) |>
  select(-prez_gop,-prez_dem,-day)

# add a key of date, set day "01" as fault. 
#pols_data$date <- as.Date(paste("01",match(pols_data$month, month.name),pols_data$year,sep = " "),format = "%d %m %Y")
head(pols_data)
```

    ## # A tibble: 6 × 9
    ##    year month    gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##   <int> <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ## 1  1947 January       23      51     253      23      45     198 dem      
    ## 2  1947 February      23      51     253      23      45     198 dem      
    ## 3  1947 March         23      51     253      23      45     198 dem      
    ## 4  1947 April         23      51     253      23      45     198 dem      
    ## 5  1947 May           23      51     253      23      45     198 dem      
    ## 6  1947 June          23      51     253      23      45     198 dem

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
# clean the data in snp.csv
snp_data = read_csv(file = "./local_data/fivethirtyeight_datasets/snp.csv")
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(snp_data)
```

    ## # A tibble: 6 × 2
    ##   date   close
    ##   <chr>  <dbl>
    ## 1 7/1/15 2080.
    ## 2 6/1/15 2063.
    ## 3 5/1/15 2107.
    ## 4 4/1/15 2086.
    ## 5 3/2/15 2068.
    ## 6 2/2/15 2104.

``` r
tail(snp_data)
```

    ## # A tibble: 6 × 2
    ##   date   close
    ##   <chr>  <dbl>
    ## 1 6/1/50  17.7
    ## 2 5/1/50  18.8
    ## 3 4/3/50  18.0
    ## 4 3/1/50  17.3
    ## 5 2/1/50  17.2
    ## 6 1/3/50  17.0

``` r
# we can see that the Date is from latest to previous. So the latest year is 2015 and the previous year is 1950.

# break up the variable date
snp_data <- separate(snp_data,date,into = c("month","day","year"),sep = '/')
snp_data$year <- as.integer(snp_data$year)
snp_data$month <- as.integer(snp_data$month)
snp_data$day <- as.integer(snp_data$day)
snp_data$year <- ifelse(snp_data$year > 15, 1900 + snp_data$year, 2000 + snp_data$year)

# order the data
snp_data <- snp_data |>
  arrange(year,month) |>
  select(year,month,everything()) |>
  select(-day)

# replace month number with month name
snp_data$month <- month.name[snp_data$month]

# add a key of date, set day "01" as fault. 
#snp_data$date <- as.Date(paste("01",match(snp_data$month, month.name),snp_data$year,sep = " "),format = "%d %m %Y")
head(snp_data)
```

    ## # A tibble: 6 × 3
    ##    year month    close
    ##   <dbl> <chr>    <dbl>
    ## 1  1950 January   17.0
    ## 2  1950 February  17.2
    ## 3  1950 March     17.3
    ## 4  1950 April     18.0
    ## 5  1950 May       18.8
    ## 6  1950 June      17.7

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemploy_data = read_csv(file = "./local_data/fivethirtyeight_datasets/unemployment.csv")
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
#switching from “wide” to “long” format
unemploy_data  <- pivot_longer(
  unemploy_data,
  Jan:Dec,
  names_to = "month",
  values_to = "percentage of unemployment"
  ) 

unemploy_data <- rename(unemploy_data,year = Year)
unemploy_data$year <- as.integer(unemploy_data$year)

# change abbreviate into full name
unemploy_data$month <- month.name[match(unemploy_data$month,month.abb)]

# add a key of date, set day "01" as fault. 
#unemploy_data$date <- as.Date(paste("01",match(unemploy_data$month, month.name),unemploy_data$year,sep = " "),format = "%d %m %Y")

head(unemploy_data)
```

    ## # A tibble: 6 × 3
    ##    year month    `percentage of unemployment`
    ##   <int> <chr>                           <dbl>
    ## 1  1948 January                           3.4
    ## 2  1948 February                          3.8
    ## 3  1948 March                             4  
    ## 4  1948 April                             3.9
    ## 5  1948 May                               3.5
    ## 6  1948 June                              3.6

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
merged_data <- merge(pols_data, snp_data, by = c("year","month"), all.x = TRUE)
final_data <- merge(merged_data,unemploy_data,by = c("year","month"), all.x = TRUE)
head(final_data)
```

    ##   year    month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ## 1 1947    April      23      51     253      23      45     198       dem    NA
    ## 2 1947   August      23      51     253      23      45     198       dem    NA
    ## 3 1947 December      24      51     253      23      45     198       dem    NA
    ## 4 1947 February      23      51     253      23      45     198       dem    NA
    ## 5 1947  January      23      51     253      23      45     198       dem    NA
    ## 6 1947     July      23      51     253      23      45     198       dem    NA
    ##   percentage of unemployment
    ## 1                         NA
    ## 2                         NA
    ## 3                         NA
    ## 4                         NA
    ## 5                         NA
    ## 6                         NA

``` r
summary(final_data)
```

    ##       year         month              gov_gop         sen_gop    
    ##  Min.   :1947   Length:822         Min.   :12.00   Min.   :32.0  
    ##  1st Qu.:1964   Class :character   1st Qu.:18.00   1st Qu.:42.0  
    ##  Median :1981   Mode  :character   Median :22.00   Median :46.0  
    ##  Mean   :1981                      Mean   :22.48   Mean   :46.1  
    ##  3rd Qu.:1998                      3rd Qu.:28.00   3rd Qu.:51.0  
    ##  Max.   :2015                      Max.   :34.00   Max.   :56.0  
    ##                                                                  
    ##     rep_gop         gov_dem        sen_dem         rep_dem   
    ##  Min.   :141.0   Min.   :17.0   Min.   :44.00   Min.   :188  
    ##  1st Qu.:176.0   1st Qu.:22.0   1st Qu.:48.00   1st Qu.:211  
    ##  Median :195.0   Median :28.0   Median :53.00   Median :250  
    ##  Mean   :194.9   Mean   :27.2   Mean   :54.41   Mean   :245  
    ##  3rd Qu.:222.0   3rd Qu.:32.0   3rd Qu.:58.00   3rd Qu.:268  
    ##  Max.   :253.0   Max.   :41.0   Max.   :71.00   Max.   :301  
    ##                                                              
    ##   president             close         percentage of unemployment
    ##  Length:822         Min.   :  17.05   Min.   : 2.50             
    ##  Class :character   1st Qu.:  83.67   1st Qu.: 4.70             
    ##  Mode  :character   Median : 137.26   Median : 5.60             
    ##                     Mean   : 472.85   Mean   : 5.83             
    ##                     3rd Qu.: 932.06   3rd Qu.: 6.90             
    ##                     Max.   :2107.39   Max.   :10.80             
    ##                     NA's   :36        NA's   :12

``` r
dim(final_data)
```

    ## [1] 822  11

Write a short paragraph about these datasets. Explain briefly what each
dataset contained, and describe the resulting dataset (e.g. give the
dimension, range of years, and names of key variables).

Note: we could have used a date variable as a key instead of creating
year and month keys; doing so would help with some kinds of plotting,
and be a more accurate representation of the data. Date formats are
tricky, though. For more information check out the lubridate package in
the tidyverse.

Answer:This analysis used three datasets: “snp,” “pols-month,” and
“unemployment.” There are 822 observations of 9 variables in the file
“pols-month” that are related to whether there are currently more
republican or democratic national politicians. The range of the year is
from 1947 to 2015. The key variables are
mon,prez_gop,gov_gop,sen_gop,rep_gop,prez_dem,gov_dem,sen_dem,rep_dem.

There are 787 observations of 2 variables in the file “snp”.The range of
the year is from 1950 to 2015. The Standard & Poor’s stock market index,
which is frequently used as a representative indicator of the entire
stock market, is one of the two variables. Names of key variables are
close, date.

In the “unemployment” file, there are 68 observations of 13 variables
that relate to the percentage of unemployment over time.The range of the
year(date) is from 1948 Jan to 2015 Jun. Names of key variables are
Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec.

The resulting dataset has 822 observations of 11 variables. The range of
years is from 1947 to 2015. Names of key variables are
year,month,gov_gop,sen_gop,rep_gop,gov_dem,president,close,percentage of
unemployment. Year and month represent the time. Close is the closing
values of the S&P stock index on the associated date.

## Problem 2

This problem uses the Mr. Trash Wheel dataset, available as an Excel
file on the course website.

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read_excel,use reasonable variable names,omit rows that do not include
dumpster-specific data

The data include a column for the (approximate) number of homes powered.
This calculation is described in the Homes powered note, but not applied
to every row in the dataset. Update the data to include a new
homes_powered variable based on this calculation.

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

``` r
library(readxl)
# import and clean mr.trash wheel
mr_data = read_excel("./local_data/202309 Trash Wheel Collection Data.xlsx",sheet ="Mr. Trash Wheel") |>
    janitor::clean_names()
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
tail(mr_data, 5)
```

    ## # A tibble: 5 × 16
    ##   dumpster month year  date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ## 1      581 June  2023  2023-06-28 00:00:00        3.56                 15
    ## 2      582 June  2023  2023-06-28 00:00:00        3.79                 15
    ## 3      583 June  2023  2023-06-28 00:00:00        2.28                 10
    ## 4      584 June  2023  2023-06-29 00:00:00        3.9                  15
    ## 5       NA <NA>  <NA>  NA                      1875.                 8934
    ## # ℹ 10 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, x15 <lgl>,
    ## #   x16 <lgl>

``` r
mr_data <- mr_data |> 
  filter(!is.na(dumpster)) |>
  select(-x15,-x16)
mr_data$year <- as.numeric(mr_data$year)
# Homes Powered - Each ton of trash equates to on average 500 kilowatts of electricity.  An average household will use 30 kilowatts per day.
mr_data$homes_powered <- round(500*mr_data$weight_tons/30,2)
mr_data$trash_wheel <- "Mr.Trash Wheel"

# import and clean Professor Trash Wheel
professor_data = read_excel("./local_data/202309 Trash Wheel Collection Data.xlsx",sheet ="Professor Trash Wheel") |>
    janitor::clean_names()

professor_data <- professor_data |> 
  filter(!is.na(dumpster))
tail(professor_data, 5)
```

    ## # A tibble: 5 × 13
    ##   dumpster month     year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ## 1      102 February  2023 2023-02-15 00:00:00        2.41                 15
    ## 2      103 April     2023 2023-04-10 00:00:00        2.05                 15
    ## 3      104 April     2023 2023-04-20 00:00:00        2.58                 15
    ## 4      105 June      2023 2023-06-16 00:00:00        1.85                 15
    ## 5      106 June      2023 2023-06-29 00:00:00        2.25                 15
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

``` r
professor_data$homes_powered <- round(500*professor_data$weight_tons/30,2)
professor_data$trash_wheel <- "Professor Trash Wheel"

# import and clean Gwynnda Trash Wheel
gw_data = read_excel("./local_data/202309 Trash Wheel Collection Data.xlsx",sheet ="Gwynnda Trash Wheel") |>
    janitor::clean_names()

gw_data <- gw_data |> 
  filter(!is.na(dumpster))

gw_data$homes_powered <- round(500*gw_data$weight_tons/30,2)
gw_data$trash_wheel <- "Gwynnda Trash Wheel"
tail(gw_data, 5)
```

    ## # A tibble: 5 × 13
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1      150 June   2023 2023-06-29 00:00:00        2.74                 15
    ## 2      151 June   2023 2023-06-29 00:00:00        3.12                 15
    ## 3      152 June   2023 2023-06-29 00:00:00        3.12                 15
    ## 4      153 June   2023 2023-06-29 00:00:00        3.45                 15
    ## 5      154 June   2023 2023-06-30 00:00:00        2.88                 15
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>, trash_wheel <chr>

``` r
# combine dataset
merged_wheel <- bind_rows(mr_data, professor_data,gw_data)
summary(merged_wheel)
```

    ##     dumpster      month                year     
    ##  Min.   :  1   Length:845         Min.   :2014  
    ##  1st Qu.: 71   Class :character   1st Qu.:2017  
    ##  Median :162   Mode  :character   Median :2019  
    ##  Mean   :223                      Mean   :2019  
    ##  3rd Qu.:373                      3rd Qu.:2021  
    ##  Max.   :584                      Max.   :2023  
    ##                                                 
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :1900-01-20 00:00:00.00   Min.   :0.610   Min.   : 5.00     
    ##  1st Qu.:2017-06-21 00:00:00.00   1st Qu.:2.490   1st Qu.:15.00     
    ##  Median :2019-10-25 00:00:00.00   Median :3.070   Median :15.00     
    ##  Mean   :2019-06-08 04:53:06.75   Mean   :3.009   Mean   :15.13     
    ##  3rd Qu.:2021-11-04 00:00:00.00   3rd Qu.:3.540   3rd Qu.:15.00     
    ##  Max.   :2023-06-30 00:00:00.00   Max.   :5.620   Max.   :20.00     
    ##                                                                     
    ##  plastic_bottles  polystyrene    cigarette_butts  glass_bottles   
    ##  Min.   :   0    Min.   :    0   Min.   :     0   Min.   :  0.00  
    ##  1st Qu.:1000    1st Qu.:  280   1st Qu.:  3200   1st Qu.: 10.00  
    ##  Median :1980    Median :  950   Median :  5500   Median : 18.00  
    ##  Mean   :2296    Mean   : 1631   Mean   : 15592   Mean   : 20.89  
    ##  3rd Qu.:2900    3rd Qu.: 2400   3rd Qu.: 16000   3rd Qu.: 28.00  
    ##  Max.   :9830    Max.   :11528   Max.   :310000   Max.   :110.00  
    ##  NA's   :1       NA's   :1       NA's   :1        NA's   :156     
    ##   plastic_bags      wrappers      sports_balls   homes_powered  
    ##  Min.   :    0   Min.   :  180   Min.   : 0.00   Min.   :10.17  
    ##  1st Qu.:  280   1st Qu.:  840   1st Qu.: 6.00   1st Qu.:41.50  
    ##  Median :  680   Median : 1380   Median :11.00   Median :51.17  
    ##  Mean   : 1082   Mean   : 2330   Mean   :13.17   Mean   :50.16  
    ##  3rd Qu.: 1400   3rd Qu.: 2635   3rd Qu.:18.25   3rd Qu.:59.00  
    ##  Max.   :13450   Max.   :20100   Max.   :56.00   Max.   :93.67  
    ##  NA's   :1       NA's   :118     NA's   :261                    
    ##  trash_wheel       
    ##  Length:845        
    ##  Class :character  
    ##  Mode  :character  
    ##                    
    ##                    
    ##                    
    ## 

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in July of 2021?

``` r
nrow(merged_wheel)
```

    ## [1] 845

``` r
ncol(merged_wheel)
```

    ## [1] 15

``` r
head(merged_wheel)
```

    ## # A tibble: 6 × 15
    ##   dumpster month  year date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ## 6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, trash_wheel <chr>

Answer: There are 584 observations and 15 variables in the
`Mr.Trash Wheel`. There are 106 observations and 14 variables in the
`Professor Trash Wheel`. There are 155 observations and 13 variables in
the `Gwynnda Trash Wheel`.

In the resulting dataset `merged_wheel`, there are total 845
observations of 15 variables. Key variables are shown above by using
head() function,such as `weight_tons`,`date`,`homes_powered`. The key
variables include the date, the number or weight of different kinds of
rubbish, the total weight and so on. For example, we use the
`weight_tons` variable to represent the weight of the trash when
calculating how much energy the house would require.

``` r
sum(professor_data$weight_tons)
```

    ## [1] 216.26

The total weight of trash collected by Professor Trash Wheel was about
216.26 tons.

``` r
gw_cigarette <- filter(gw_data,year == 2021,month == "July")
sum(gw_cigarette$cigarette_butts)
```

    ## [1] 16300

The total number of cigarette butts collected by Gwynnda in July of 2021
was 1.63^{4}.

## Problem 3

This problem uses data collected in an observational study to understand
the trajectory of Alzheimer’s disease (AD) biomarkers. Study
participants were free of Mild Cognitive Impairment (MCI), a stage
between the expected cognitive decline of normal aging and the more
serious decline of dementia, at the study baseline.

Basic demographic information were measured at the study baseline. The
study monitored the development of MCI and recorded the age of MCI onset
during the follow-up period, with the last visit marking the end of
follow-up. APOE4 is a variant of the apolipoprotein E gene,
significantly associated with a higher risk of developing Alzheimer’s
disease. The amyloid β 42/40 ratio holds significant promise for
diagnosing and predicting disease outcomes. This ratio undergoes changes
over time and has been linked to the manifestation of clinical symptoms
of Alzheimer’s disease.

Import, clean, and tidy the dataset of baseline demographics. Ensure
that sex and APOE4 carrier status are appropriate encoded (i.e. not
numeric), and remove any participants who do not meet the stated
inclusion criteria (i.e. no MCI at baseline). Discuss important steps in
the import process and relevant features of the dataset. How many
participants were recruited, and of these how many develop MCI? What is
the average baseline age? What proportion of women in the study are
APOE4 carriers?

``` r
# Import, clean, and tidy the dataset of baseline demographics
baseline_data = read_csv(file = "./local_data/data_mci/MCI_baseline.csv",skip = 1)
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
dim(baseline_data)
```

    ## [1] 483   6

``` r
baseline_data <- baseline_data |>
  janitor::clean_names() |>
  mutate(
    sex = replace(sex, sex == 0, "female"),
    sex = replace(sex, sex == 1, "male"),
    apoe4 = replace(apoe4, apoe4 == 1, "Apoe4 carrier"),
    apoe4 = replace(apoe4, apoe4 == 0, "Apoe4 non-carrier"),
    ) 
baseline_data$age_at_onset <- as.numeric(baseline_data$age_at_onset)
```

    ## Warning: NAs introduced by coercion

``` r
#remove any participants who do not meet the stated inclusion criteria
baseline_filterdata <- baseline_data |> 
  mutate(age_at_onset = ifelse(age_at_onset == '.', NA, age_at_onset)) |>
  filter(current_age < age_at_onset | is.na(age_at_onset))

#participants develop MCI
mci_participants <- sum(!is.na(pull(baseline_filterdata,age_at_onset)))

proportion <- nrow(filter(baseline_filterdata,apoe4 == "Apoe4 carrier",sex == "female"))/nrow(filter(baseline_filterdata,sex == "female"))
```

Answer: First of all when importing data I start with the second line
and the first line is the description of the variable. Then for variable
name cleaning, apply mutate() and replace function as required for sex,
apoe4 re-copy, and finally exclude objects where the age_at_onset is
null.(no MCI at baseline)

479 participants were recruited and of these 93 people develop MCI.The
average baseline age is NA. In the study about 30% women in the study
are APOE4 carriers.

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

``` r
# Import, clean, and tidy the dataset of longitudinally observed biomarker values
amyloid_data = read_csv(file = "./local_data/data_mci/mci_amyloid.csv",skip = 1)
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
amyloid_data <- amyloid_data |>
  janitor::clean_names()
amyloid_data <- amyloid_data |>
 rename(id=study_id,
         year_0 = baseline,
         year_2 = time_2,
         year_4 = time_4,
         year_6 = time_6,
         year_8 = time_8) |>
  pivot_longer(
    year_0:year_8,
    names_to = "time",
    values_to = "ratio"
  ) 
amyloid_data$ratio <- as.numeric(amyloid_data$ratio)
```

    ## Warning: NAs introduced by coercion

``` r
summary(amyloid_data)
```

    ##        id            time               ratio        
    ##  Min.   :  1.0   Length:2435        Min.   :0.09938  
    ##  1st Qu.:125.0   Class :character   1st Qu.:0.10752  
    ##  Median :248.0   Mode  :character   Median :0.10967  
    ##  Mean   :248.6                      Mean   :0.10969  
    ##  3rd Qu.:372.0                      3rd Qu.:0.11187  
    ##  Max.   :495.0                      Max.   :0.11871  
    ##                                     NA's   :172

``` r
dim(amyloid_data)
```

    ## [1] 2435    3

``` r
amy_participants = length(unique(pull(amyloid_data,id)))
```

Answer: First of all when importing data I start with the second line
and the first line is the some description. Then I clean the variables’
name and I use pivot_longer() function to change the dataset to make it
more readable. I notice that the type of the variable(baseline,time_2,
time_4, time_6, time_8) is character. In order to see more details and
statistics of those varibles, i change them into numeric. The dataset
consists of 2435 observations (for an id has 5 rows, it indicates that
there are 487 participants) and 3 variables. The average of time (in
years) elapsed since the study baseline to the visit where biomarker
Amyloid \_ 42/40 ratio was measured is 0.1097 years. More details are
shown above by using summary function. And the dataset contains several
NA in different variables.

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

``` r
# find the difference between two datasets
only_baseline = anti_join(baseline_filterdata, amyloid_data,by = "id")
only_amyloid = anti_join(amyloid_data, baseline_filterdata, by = "id")

# find the different id
only_in_baseline = setdiff(baseline_filterdata$id, amyloid_data$id)
only_in_amyloid = setdiff(amyloid_data$id, baseline_filterdata$id)

merged_dataset3 <- inner_join(amyloid_data,baseline_filterdata, by = "id")
dim(merged_dataset3)
```

    ## [1] 2355    8

``` r
# the number of participants
num_participants = length(unique(pull(merged_dataset3,id)))

# Export the dataset as a CSV file
write.csv(merged_dataset3, "./local_data/mci_combined_result.csv", row.names = TRUE)
```

Some participants appear in only the baseline dataset.Participants whose
id are 14, 49, 92, 179, 268, 304, 389, 412 only appear in baseline
dataset. Total 8 participants only appear in baseline dataset.
Participants whose id are 72, 234, 283, 380, 484, 485, 486, 487, 488,
489, 490, 491, 492, 493, 494, 495 only appear in amyloid dataset. Total
16 participants only appear in baseline dataset. The resulting dataset
includes 2355 observations(which means 471 different participants) and 8
variables. The key variables include
id,baseline,time_2,time_4,time_6,time_8,current_age,sex,education,apoe4,age_at_onset.
The statistics summary is shown above.
